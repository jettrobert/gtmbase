name: Run Apify Scraper → Send to Clay (One Row Per Request)

on:
  workflow_dispatch:
    inputs:
      countryCode:
        type: string
        required: true
      deeperCityScrape:
        type: boolean
        default: false
      language:
        type: string
        default: en
      locationQuery:
        type: string
        required: true
      maxCrawledPlacesPerSearch:
        type: string
        default: "100"
      searchStringsArray:
        type: string
        required: true
        description: "Comma-separated, e.g. plumber,roofing contractor"
      skipClosedPlaces:
        type: boolean
        default: true
      searchMatching:
        type: choice
        options: [ANY, ALL]
        default: ANY
      placeMinimumStars:
        type: choice
        description: "Minimum rating (Apify format)"
        options:
          - ""
          - one
          - oneAndHalf
          - two
          - twoAndHalf
          - three
          - threeAndHalf
          - four
          - fourAndHalf
          - fourAndThreeQuarters
          - five
        default: ""
      website:
        type: choice
        options: ["", require, prefer]
        default: ""

jobs:
  scrape-and-send:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build input.json
        env:
          COUNTRY_CODE: ${{ inputs.countryCode }}
          DEEPER_CITY: ${{ inputs.deeperCityScrape }}
          LANGUAGE: ${{ inputs.language }}
          LOCATION: ${{ inputs.locationQuery }}
          MAX_PLACES: ${{ inputs.maxCrawledPlacesPerSearch }}
          SEARCH_STRINGS: ${{ inputs.searchStringsArray }}
          SKIP_CLOSED: ${{ inputs.skipClosedPlaces }}
          SEARCH_MATCHING: ${{ inputs.searchMatching }}
          MIN_STARS: ${{ inputs.placeMinimumStars }}
          WEBSITE_FILTER: ${{ inputs.website }}
        run: |
          IFS=',' read -ra ARR <<< "$SEARCH_STRINGS"
          SEARCH_JSON=$(printf '%s\n' "${ARR[@]}" | jq -R . | jq -s -c .)

          cat << EOF > input.json
          {
            "countryCode": "$COUNTRY_CODE",
            "deeperCityScrape": $DEEPER_CITY,
            "language": "$LANGUAGE",
            "locationQuery": "$LOCATION",
            "maxCrawledPlacesPerSearch": $MAX_PLACES,
            "searchStringsArray": $SEARCH_JSON,
            "skipClosedPlaces": $SKIP_CLOSED,
            "searchMatching": "$SEARCH_MATCHING",
            "placeMinimumStars": "$MIN_STARS",
            "website": "$WEBSITE_FILTER"
          }
          EOF
          echo "input.json ready"
          cat input.json | jq .

      - name: Run Apify (sync)
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        run: |
          curl -f -X POST \
            "https://api.apify.com/v2/acts/compass~google-maps-extractor/run-sync-get-dataset-items?token=$APIFY_TOKEN&memory=8192" \
            -H "Content-Type: application/json" \
            --data @input.json \
            -o results.json

          COUNT=$(jq '. | length' results.json)
          echo "Apify returned $COUNT places"

      - name: Send each place as a separate row to Clay
        env:
          CLAY_WEBHOOK: ${{ secrets.CLAY_WEBHOOK }}
        run: |
          echo "Sending rows one-by-one to Clay..."

          jq -c '.[]' results.json | while read -r row; do
            echo "$row" | curl -X POST "$CLAY_WEBHOOK" \
              -H "Content-Type: application/json" \
              -d @- 
            
            # Be gentle with Clay's rate limits (Clay allows ~30–50 req/sec, 10/sec is safe)
            sleep 0.1
          done

          echo "All rows successfully sent to Clay as individual rows!"
