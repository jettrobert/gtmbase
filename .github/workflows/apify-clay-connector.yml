name: Clay → Apify → Clay (scalable + minimal payload)

on:
  workflow_dispatch:
    inputs:
      countryCode: { type: string, default: "us" }
      deeperCityScrape: { type: string, default: "true" }
      language: { type: string, default: "en" }
      skipClosedPlaces: { type: string, default: "true" }
      searchMatching: { type: string, default: "ALL" }
      placeMinimumStars: { type: string, default: "threeAndHalf" }
      website: { type: string, default: "require" }
      locationQuery: { type: string, required: true }
      maxCrawledPlacesPerSearch: { type: string, default: "50" }
      searchStringsArray: { type: string, default: "Christmas market" }

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
      CLAY_WEBHOOK_URL: ${{ secrets.CLAY_WEBHOOK }}

    steps:
      - name: Create Apify input.json
        env:
          LOC: ${{ inputs.locationQuery }}
          MAX: ${{ inputs.maxCrawledPlacesPerSearch }}
          TERMS: ${{ inputs.searchStringsArray }}
        run: |
          SEARCH_ARRAY=$(echo "$TERMS" | jq -R 'split(",") | map(select(length>0) | gsub("^\\s+|\\s+$";""))')
          cat > input.json << EOF
          {
            "countryCode": "us",
            "deeperCityScrape": true,
            "language": "en",
            "locationQuery": "$LOC",
            "maxCrawledPlacesPerSearch": ${MAX:-50},
            "searchStringsArray": $SEARCH_ARRAY,
            "skipClosedPlaces": true,
            "searchMatching": "all",
            "placeMinimumStars": "threeAndHalf",
            "website": "withWebsite",
            "memoryMbytes": 8192
          }
          EOF

      - name: Run Apify actor
        run: |
          RUN_JSON=$(curl -s -X POST \
            "https://api.apify.com/v2/acts/compass~google-maps-extractor/runs?token=$APIFY_TOKEN" \
            -H "Content-Type: application/json" \
            --data @input.json)

          RUN_ID=$(echo "$RUN_JSON" | jq -r '.data.id')
          DATASET_ID=$(echo "$RUN_JSON" | jq -r '.data.defaultDatasetId')

          while true; do
            STATUS=$(curl -s "https://api.apify.com/v2/actor-runs/$RUN_ID?token=$APIFY_TOKEN" | jq -r '.data.status')
            echo "Status: $STATUS"
            [[ "$STATUS" == "SUCCEEDED" ]] && break
            [[ "$STATUS" == "FAILED" || "$STATUS" == "ABORTED" ]] && exit 1
            sleep 7
          done

          curl -s "https://api.apify.com/v2/datasets/$DATASET_ID/items?format=json&clean=1&token=$APIFY_TOKEN" \
            > full-results.json

      - name: Send fields to Clay in batches
        run: |
          jq 'map({
            title,
            url,
            placeId,
            categoryName,
            website,
            cid,
            address,
            street,
            city,
            postalCode,
            state,
            phone,
            reviewsCount,
            totalScore,
            price,
            permanentlyClosed,
            openingHours,
            scrapedAt
          })' full-results.json > minimal.json

          TOTAL=$(jq 'length' minimal.json)
          echo "Sending $TOTAL places (only required fields) in batches of 60…"

          jq -c '.[]' minimal.json | split -l 60 - batch_

          SENT=0
          for file in batch_*; do
            jq -s . "$file" > payload.json
            curl -X POST "$CLAY_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              --data @payload.json
            SENT=$((SENT + $(jq 'length' payload.json)))
            echo "Sent batch → $SENT/$TOTAL"
            rm "$file" payload.json
            sleep 0.8
          done

          echo "SUCCESS → All $TOTAL rows added to Clay"
