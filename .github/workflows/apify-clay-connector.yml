name: Run Apify Scraper and Send to Clay

on:
  workflow_dispatch:
    inputs:
      countryCode:
        type: string
        required: true
        description: "e.g. US, DE, FR"
      deeperCityScrape:
        type: boolean
        default: false
      language:
        type: string
        default: en
      locationQuery:
        type: string
        required: true
        description: "e.g. Berlin, Germany or Miami, FL"
      maxCrawledPlacesPerSearch:
        type: string
        default: "100"
      searchStringsArray:
        type: string
        required: true
        description: "Comma-separated, e.g. dentist,orthodontist,dental clinic"
      skipClosedPlaces:
        type: boolean
        default: true
      searchMatching:
        type: choice
        options: [ANY, ALL]
        default: ANY
      placeMinimumStars:
        type: choice
        description: "Minimum Google rating filter (Apify format)"
        options:
          - ""
          - one
          - oneAndHalf
          - two
          - twoAndHalf
          - three
          - threeAndHalf
          - four
          - fourAndHalf
          - fourAndThreeQuarters
          - five
        default: ""
      website:
        type: choice
        options: ["", require, prefer]
        default: ""

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build correct input.json (with proper placeMinimumStars string)
        env:
          COUNTRY_CODE: ${{ inputs.countryCode }}
          DEEPER_CITY: ${{ inputs.deeperCityScrape }}
          LANGUAGE: ${{ inputs.language }}
          LOCATION: ${{ inputs.locationQuery }}
          MAX_PLACES: ${{ inputs.maxCrawledPlacesPerSearch }}
          SEARCH_STRINGS: ${{ inputs.searchStringsArray }}
          SKIP_CLOSED: ${{ inputs.skipClosedPlaces }}
          SEARCH_MATCHING: ${{ inputs.searchMatching }}
          MIN_STARS: ${{ inputs.placeMinimumStars }}
          WEBSITE_FILTER: ${{ inputs.website }}
        run: |
          # Split search strings into real JSON array
          IFS=',' read -ra ARR <<< "$SEARCH_STRINGS"
          SEARCH_JSON=$(printf '%s\n' "${ARR[@]}" | jq -R . | jq -s -c .)

          # Build JSON – note MIN_STARS is already the correct string like "fourAndHalf"
          cat << EOF > input.json
          {
            "countryCode": "$COUNTRY_CODE",
            "deeperCityScrape": $DEEPER_CITY,
            "language": "$LANGUAGE",
            "locationQuery": "$LOCATION",
            "maxCrawledPlacesPerSearch": $MAX_PLACES,
            "searchStringsArray": $SEARCH_JSON,
            "skipClosedPlaces": $SKIP_CLOSED,
            "searchMatching": "$SEARCH_MATCHING",
            "placeMinimumStars": "$MIN_STARS",
            "website": "$WEBSITE_FILTER"
          }
          EOF

          echo "Generated input.json:"
          cat input.json | jq .

      - name: Run Apify Google Maps Extractor
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        run: |
          echo "Starting Apify run..."
          curl -f -X POST \
            "https://api.apify.com/v2/acts/compass~google-maps-extractor/run-sync-get-dataset-items?token=$APIFY_TOKEN&memory=8192" \
            -H "Content-Type: application/json" \
            --data @input.json \
            -o results.json || { echo "Apify request failed"; exit 1; }

          COUNT=$(jq '. | length' results.json)
          echo "Successfully scraped $COUNT places"

          [ "$COUNT" -eq 0 ] && echo "Warning: No places found – try broadening your filters" || echo "Results ready to send"

      - name: Send to Clay
        env:
          CLAY_WEBHOOK: ${{ secrets.CLAY_WEBHOOK }}
        run: |
          echo "Pushing $(jq '. | length' results.json) rows to Clay..."
          curl -X POST "$CLAY_WEBHOOK" \
            -H "Content-Type: application/json" \
            --data @results.json

          sleep 2
          echo "All leads are now in your Clay table!"
