name: Run Apify Scraper and Send to Clay

on:
  workflow_dispatch:
    inputs:
      countryCode:
        type: string
        required: true
        description: "e.g. US, DE, FR"
      deeperCityScrape:
        type: boolean
        default: false
      language:
        type: string
        default: en
      locationQuery:
        type: string
        required: true
        description: "e.g. Berlin, Germany"
      maxCrawledPlacesPerSearch:
        type: string
        default: "100"
      searchStringsArray:
        type: string
        required: true
        description: "Comma-separated, e.g. dentist,orthodontist"
      skipClosedPlaces:
        type: boolean
        default: true
      searchMatching:
        type: choice
        options: [ANY, ALL]
        default: ANY
      placeMinimumStars:
        type: string
        default: "0"
        description: "Minimum rating as string, e.g. 4.0 or 4.5"
      website:
        type: choice
        options: ["", require, prefer]
        default: ""

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build input.json (with proper JSON types)
        env:
          COUNTRY_CODE: ${{ inputs.countryCode }}
          DEEPER_CITY: ${{ inputs.deeperCityScrape }}
          LANGUAGE: ${{ inputs.language }}
          LOCATION: ${{ inputs.locationQuery }}
          MAX_PLACES: ${{ inputs.maxCrawledPlacesPerSearch }}
          SEARCH_STRINGS: ${{ inputs.searchStringsArray }}
          SKIP_CLOSED: ${{ inputs.skipClosedPlaces }}
          SEARCH_MATCHING: ${{ inputs.searchMatching }}
          MIN_STARS: ${{ inputs.placeMinimumStars }}   # ← kept as string
          WEBSITE_FILTER: ${{ inputs.website }}
        run: |
          # Split search strings into real JSON array
          IFS=',' read -ra ARR <<< "$SEARCH_STRINGS"
          SEARCH_JSON=$(printf '%s\n' "${ARR[@]}" | jq -R . | jq -s -c .)

          cat << EOF > input.json
          {
            "countryCode": "$COUNTRY_CODE",
            "deeperCityScrape": $DEEPER_CITY,
            "language": "$LANGUAGE",
            "locationQuery": "$LOCATION",
            "maxCrawledPlacesPerSearch": $(echo "$MAX_PLACES" | jq -R .),
            "searchStringsArray": $SEARCH_JSON,
            "skipClosedPlaces": $SKIP_CLOSED,
            "searchMatching": "$SEARCH_MATCHING",
            "placeMinimumStars": "$MIN_STARS",
            "website": "$WEBSITE_FILTER"
          }
          EOF

          echo "Generated input.json:"
          jq . input.json

      - name: Run Apify Google Maps Extractor
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
        run: |
          echo "Calling Apify (sync mode)..."
          curl -s -X POST \
            "https://api.apify.com/v2/acts/compass~google-maps-extractor/run-sync-get-dataset-items?token=$APIFY_TOKEN&memory=8192" \
            -H "Content-Type: application/json" \
            --data @input.json \
            -o results.json

          COUNT=$(jq '. | length' results.json)
          echo "Apify returned $COUNT places"

          [ "$COUNT" -eq 0 ] && echo "No results – check your filters" && exit 1

      - name: Send to Clay
        env:
          CLAY_WEBHOOK: ${{ secrets.CLAY_WEBHOOK }}
        run: |
          echo "Sending $COUNT rows to Clay..."
          curl -X POST "$CLAY_WEBHOOK" \
            -H "Content-Type: application/json" \
            --data @results.json

          sleep 2
          echo "All done – leads are in Clay!"
