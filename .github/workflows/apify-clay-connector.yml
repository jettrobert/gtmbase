name: Run Apify Scraper and Send to Clay

on:
  workflow_dispatch:
    inputs:
      countryCode:
        description: "Country code (e.g., us)"
        required: true
        type: string
      deeperCityScrape:
        description: "Enable deeper city scrape"
        required: true
        type: boolean
      language:
        description: "Language code (e.g., en)"
        required: true
        type: string
      locationQuery:
        description: "Location query (e.g., Tennessee, us)"
        required: true
        type: string
      maxCrawledPlacesPerSearch:
        description: "Max crawled places per search"
        required: true
        type: string
      searchStringsArray:
        description: "Comma-separated search strings"
        required: true
        type: string
      skipClosedPlaces:
        description: "Skip closed places"
        required: true
        type: boolean
      searchMatching:
        description: "Search matching mode (all / any)"
        required: true
        type: string
      placeMinimumStars:
        description: "Minimum stars"
        required: true
        type: string
      website:
        description: "Website filter"
        required: true
        type: string

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Run scraper
        env:
          APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
          CLAY_WEBHOOK: ${{ secrets.CLAY_WEBHOOK }}

          COUNTRY_CODE: ${{ github.event.inputs.countryCode }}
          DEEPER_CITY: ${{ github.event.inputs.deeperCityScrape }}
          LANGUAGE: ${{ github.event.inputs.language }}
          LOCATION: ${{ github.event.inputs.locationQuery }}
          MAX_PLACES: ${{ github.event.inputs.maxCrawledPlacesPerSearch }}
          SEARCH_STRINGS: ${{ github.event.inputs.searchStringsArray }}
          SKIP_CLOSED: ${{ github.event.inputs.skipClosedPlaces }}
          SEARCH_MATCHING: ${{ github.event.inputs.searchMatching }}
          MIN_STARS: ${{ github.event.inputs.placeMinimumStars }}
          WEBSITE_FILTER: ${{ github.event.inputs.website }}

        run: |
          echo "üì° Starting Apify scrape..."

          # Convert INPUTS ‚Üí JSON ‚Üí input.json
          cat <<EOF > input.json
{
  "countryCode": "${COUNTRY_CODE}",
  "deeperCityScrape": ${DEEPER_CITY},
  "language": "${LANGUAGE}",
  "locationQuery": "${LOCATION}",
  "maxCrawledPlacesPerSearch": ${MAX_PLACES},
  "searchStringsArray": ["${SEARCH_STRINGS}"],
  "skipClosedPlaces": ${SKIP_CLOSED},
  "searchMatching": "${SEARCH_MATCHING}",
  "placeMinimumStars": "${MIN_STARS}",
  "website": "${WEBSITE_FILTER}"
}
EOF

          echo "üìù Generated input.json:"
          cat input.json

          echo "üöÄ Triggering Apify actor..."
          curl -s -X POST \
            "https://api.apify.com/v2/acts/compass~google-maps-extractor/run-sync-get-dataset-items?token=$APIFY_TOKEN&memory=4096" \
            -H "Content-Type: application/json" \
            --data @input.json \
            -o results.json

          echo "üì• Apify results:"
          cat results.json

          echo "üì§ Sending results to Clay webhook..."
          curl -s -X POST "$CLAY_WEBHOOK" \
            -H "Content-Type: application/json" \
            --data @results.json

          echo "üéâ Done!"
